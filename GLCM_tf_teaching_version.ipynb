{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# image = (batch, width, height, channel) (assumed)\n",
    "# GLCM_subarray = (batch, width', height', channel, l_for_GLCM, l_for_GLCM, l_for_Lagrange_polynomial, l_for_Lagrange_polynomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs\n",
      "[[2 2 2]\n",
      " [0 0 2]\n",
      " [2 1 2]]\n",
      "image_shape =  (1, 3, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "# an instance of input\n",
    "inputs = np.random.randint(0, 3, size=(1, 3, 3, 1))\n",
    "print(\"inputs\")\n",
    "inputs_for_test = np.reshape(inputs, (3, 3))\n",
    "print(inputs_for_test)\n",
    "image = tf.constant(inputs, dtype=tf.float32)\n",
    "\n",
    "#some parameters of GLCM\n",
    "level = 3\n",
    "distance = 2\n",
    "angle = math.pi\n",
    "symmetric = True\n",
    "normed = True\n",
    "\n",
    "# Most of time, we will only know batch_size while executing time, \n",
    "# however, to do tf.reshape and tf.tile, we have to fix it first.\n",
    "batch_size = inputs.shape[0]\n",
    "\n",
    "#make image to be regularized to the fixed levels.\n",
    "image = tf.cast(image/(3/level), dtype=tf.int32)\n",
    "#image = tf.cast(image, dtype=tf.float32)\n",
    "\n",
    "#print(\"Check some value: \")\n",
    "#print(K.eval(image[0][0:5][0:5]))\n",
    "\n",
    "print(\"image_shape = \", image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.16666667]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.16666667  0.          0.66666667]]\n"
     ]
    }
   ],
   "source": [
    "#Check answer with skimage\n",
    "from skimage.feature import greycomatrix\n",
    "\n",
    "glcm = greycomatrix(inputs_for_test, distances=[2], angles=[math.pi], levels=3, symmetric=True, normed=True)\n",
    "\n",
    "#To make it better to read, we reshaped it.\n",
    "print(np.reshape(glcm, (glcm.shape[0], glcm.shape[1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subarray_1.shape:  (1, 3, 1, 1)\n",
      "subarray_2.shape:  (1, 3, 1, 1)\n",
      "Subarray_1: \n",
      "[[2]\n",
      " [2]\n",
      " [2]]\n",
      "Subarray_2: \n",
      "[[2]\n",
      " [0]\n",
      " [2]]\n"
     ]
    }
   ],
   "source": [
    "#get some parameters from image\n",
    "batch = batch_size\n",
    "rows = image.shape[1].value\n",
    "cols = image.shape[2].value\n",
    "channel = image.shape[3].value\n",
    "\n",
    "\n",
    "#calculate the subarray size of image \n",
    "row = int(round(np.sin(angle))) * distance\n",
    "col = int(round(np.cos(angle))) * distance\n",
    "\n",
    "#We have two subarrays with same shape to express the two distinct entries\n",
    "#We wil use Matrix operations instead of for-loop and if, for the ban on them from tensorflow. \n",
    "if col > 0:\n",
    "    subarray_1 = image[:, :rows-row, :cols-col, :]\n",
    "    subarray_2 = image[:, row:, col:, :]\n",
    "else:\n",
    "    subarray_1 = image[:, :rows-row, -col:, :]\n",
    "    subarray_2 = image[:, row:, :cols+col, :]\n",
    "\n",
    "print(\"subarray_1.shape: \", subarray_1.shape)\n",
    "print(\"subarray_2.shape: \", subarray_2.shape)\n",
    "\n",
    "# get someparameters from subarray, too.\n",
    "sub_row = subarray_1.shape[1].value\n",
    "sub_column = subarray_1.shape[2].value\n",
    "\n",
    "print(\"Subarray_1: \")\n",
    "print(K.eval(tf.reshape(subarray_1, (subarray_1.shape[1].value, subarray_1.shape[2].value))))\n",
    "print(\"Subarray_2: \")\n",
    "print(K.eval(tf.reshape(subarray_2, (subarray_2.shape[1].value, subarray_2.shape[2].value))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshaped_subarray_1:  Tensor(\"Reshape_2:0\", shape=(1, 3, 1, 1, 1), dtype=int32)\n",
      "reshaped_subarray_2:  Tensor(\"Reshape_3:0\", shape=(1, 3, 1, 1, 1), dtype=int32)\n",
      "reshape_tiled_subarray_1:  Tensor(\"Reshape_4:0\", shape=(1, 3, 1, 1, 3, 3, 2), dtype=int32)\n",
      "reshape_tiled_subarray_2 Tensor(\"Reshape_5:0\", shape=(1, 3, 1, 1, 3, 3, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# To implement Lagrange polynomial, and the calculation on every entry of GLCM, \n",
    "# subarrays have to be reshaped and tiled the as\n",
    "# (batch, width', height', channel, level_for_GLCM, level_for_GLCM, level-1_for_Lagrange_polynomial)\n",
    "# two level_for_GLCM is because of a_{i, j}, \n",
    "# and level_for_Lagrange_polynomial is for (0, ... , level-1), but only pick (level-1) distinct values in Lagrange polynomials.\n",
    "\n",
    "# For tensorflow can only tile for dim<5, we will do like: \"tile->reshape\" most of time.\n",
    "\n",
    "reshaped_subarray_1 = tf.reshape(subarray_1, shape=(batch, sub_row, sub_column, channel, 1))\n",
    "reshaped_subarray_2 = tf.reshape(subarray_2, shape=(batch, sub_row, sub_column, channel, 1))\n",
    "\n",
    "print(\"reshaped_subarray_1: \", reshaped_subarray_1)\n",
    "print(\"reshaped_subarray_2: \", reshaped_subarray_2)\n",
    "\n",
    "tiled_subarray_1 = tf.tile(reshaped_subarray_1, [1, 1, 1, 1, level*level*(level-1)])\n",
    "tiled_subarray_2 = tf.tile(reshaped_subarray_2, [1, 1, 1, 1, level*level*(level-1)])\n",
    "\n",
    "reshape_tiled_subarray_1 = tf.reshape(tiled_subarray_1, shape=(batch, sub_row, sub_column, channel, level, level, level-1))\n",
    "reshape_tiled_subarray_2 = tf.reshape(tiled_subarray_2, shape=(batch, sub_row, sub_column, channel, level, level, level-1))\n",
    "\n",
    "print(\"reshape_tiled_subarray_1: \", reshape_tiled_subarray_1)\n",
    "print(\"reshape_tiled_subarray_2\", reshape_tiled_subarray_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence_rev: \n",
      "[[1 2]\n",
      " [0 2]\n",
      " [0 1]]\n",
      "Tensor(\"ReverseV2:0\", shape=(3, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Now, to calculate the GLCM, we need a sequence constant in (0, ... , level-1).\n",
    "# To applied matrix operation on it, we need to initial it in Tensor type.\n",
    "\n",
    "# For it is so complicated to initial in pure tensorflow functions, we use numpy array first.\n",
    "# Important: it is OK to use some python or numpy functions in tensorflow,\n",
    "# but can't be done with functions that depends on back propogation.\n",
    "\n",
    "#define the shape of sequence, which is something like: \n",
    "# [0, 1, 2, ... , level-1] \n",
    "# [0, 1, 2, ... , level-1]          \n",
    "# [0, 1, 2, ... , level-1]\n",
    "#           .\n",
    "#           .\n",
    "#           .\n",
    "# and delete i at ith row. \n",
    "\n",
    "#raw sequence\n",
    "sequence = tf.constant([])\n",
    "\n",
    "for i in range(level):\n",
    "    hold = tf.ones(shape=(level-1))*i\n",
    "    sequence = tf.concat([sequence, hold], axis=0)\n",
    "    \n",
    "sequence = tf.cast(sequence, tf.int32)\n",
    "    \n",
    "#print(\"raw_sequence: \")\n",
    "#print(K.eval(sequence))\n",
    "    \n",
    "sequence_reshape = tf.reshape(sequence, (level-1, level))\n",
    "sequence_transpose = tf.transpose(sequence_reshape)\n",
    "sequence_rev = tf.reverse(sequence_transpose, [0])\n",
    "\n",
    "print(\"sequence_rev: \")\n",
    "print(K.eval(sequence_rev))\n",
    "\n",
    "print(sequence_rev)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence_rev_reshape\n",
      "[[[1 2]\n",
      "  [0 2]\n",
      "  [0 1]]\n",
      "\n",
      " [[1 2]\n",
      "  [0 2]\n",
      "  [0 1]]\n",
      "\n",
      " [[1 2]\n",
      "  [0 2]\n",
      "  [0 1]]]\n",
      "\n",
      "\n",
      "sequence_rev_reshape_tile\n",
      "(3, 3, 2)\n",
      "\n",
      "\n",
      "GLCM_t: \n",
      "[[[0 0]\n",
      "  [1 1]\n",
      "  [2 2]]\n",
      "\n",
      " [[0 0]\n",
      "  [1 1]\n",
      "  [2 2]]\n",
      "\n",
      " [[0 0]\n",
      "  [1 1]\n",
      "  [2 2]]]\n",
      "\n",
      "\n",
      "GLCM_Denominator_array[0]: \n",
      "[[-1 -2]\n",
      " [ 1 -1]\n",
      " [ 2  1]]\n",
      "\n",
      "\n",
      "GLCM_Denominator: \n",
      "[[ 2 -1  2]\n",
      " [ 2 -1  2]\n",
      " [ 2 -1  2]]\n",
      "\n",
      "\n",
      "reshape_tiled_subarray_1[0][0][0][0]: \n",
      "[[[2 2]\n",
      "  [2 2]\n",
      "  [2 2]]\n",
      "\n",
      " [[2 2]\n",
      "  [2 2]\n",
      "  [2 2]]\n",
      "\n",
      " [[2 2]\n",
      "  [2 2]\n",
      "  [2 2]]]\n",
      "GLCM_Numerator_1_array[0]: \n",
      "[[1 0]\n",
      " [2 0]\n",
      " [2 1]]\n",
      "GLCM_Numerator_1: \n",
      "[[0 0 2]\n",
      " [0 0 2]\n",
      " [0 0 2]]\n",
      "\n",
      "\n",
      "GLCM_Single_Entry: \n",
      "[[ 0. -0.  1.]\n",
      " [ 0. -0.  1.]\n",
      " [ 0. -0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "# To show the arrays of each step, we show it in a single entry case.\n",
    "# It will take a longer time to run while taking a single ertry from raw image, \n",
    "# please wait patiently.\n",
    "\n",
    "#tile it(Demo version)\n",
    "sequence_rev_reshape = tf.reshape(sequence_rev, (1, level, level-1))\n",
    "sequence_rev_reshape_tile = tf.tile(sequence_rev_reshape, [level, 1, 1])\n",
    "\n",
    "print(\"sequence_rev_reshape\")\n",
    "print(K.eval(sequence_rev_reshape_tile))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"sequence_rev_reshape_tile\")\n",
    "print(sequence_rev_reshape_tile.shape)\n",
    "print(\"\\n\")\n",
    "\n",
    "#GLCM_Denominator(Demo version)\n",
    "sequence_Denominator_reshape = tf.reshape(sequence, (level, level-1))\n",
    "GLCM_t = tf.tile(tf.reshape(sequence_Denominator_reshape, (1, level, level-1)), [level, 1, 1])\n",
    "print(\"GLCM_t: \")\n",
    "print(K.eval(GLCM_t))\n",
    "print(\"\\n\")\n",
    "\n",
    "GLCM_Denominator_array = GLCM_t-sequence_rev_reshape_tile\n",
    "GLCM_Denominator = tf.reduce_prod(GLCM_Denominator_array, axis=2)\n",
    "\n",
    "\n",
    "\n",
    "print(\"GLCM_Denominator_array[0]: \")\n",
    "print(K.eval(GLCM_Denominator_array[0]))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"GLCM_Denominator: \")\n",
    "print(K.eval(GLCM_Denominator))\n",
    "print(\"\\n\")\n",
    "\n",
    "#GLCM_Numerator(Demo version)\n",
    "GLCM_Numerator_1_array = reshape_tiled_subarray_1[0][0][0][0]-sequence_rev_reshape_tile\n",
    "GLCM_Numerator_2_array = reshape_tiled_subarray_2[0][0][0][0]-sequence_rev_reshape_tile\n",
    "\n",
    "GLCM_Numerator_1 = tf.reduce_prod(GLCM_Numerator_1_array, axis=2)\n",
    "GLCM_Numerator_2 = tf.reduce_prod(GLCM_Numerator_2_array, axis=2)\n",
    "\n",
    "print(\"reshape_tiled_subarray_1[0][0][0][0]: \")\n",
    "print(K.eval(reshape_tiled_subarray_1[0][0][0][0]))\n",
    "\n",
    "print(\"GLCM_Numerator_1_array[0]: \")\n",
    "print(K.eval(GLCM_Numerator_1_array[0]))\n",
    "\n",
    "print(\"GLCM_Numerator_1: \")\n",
    "print(K.eval(GLCM_Numerator_1))\n",
    "print(\"\\n\")\n",
    "\n",
    "#print(\"GLCM_Numerator_1\")\n",
    "#print(K.eval(GLCM_Numerator_1))\n",
    "\n",
    "# After all, the result of this step is not GLCM yet, \n",
    "# it still need to be done with some matrix operation.\n",
    "GLCM_Single_Entry = GLCM_Numerator_1/GLCM_Denominator\n",
    "print(\"GLCM_Single_Entry: \")\n",
    "print(K.eval(GLCM_Single_Entry))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence_rev_reshape\n",
      "[[[[[[1 2 0 2 0 1]]]]]]\n",
      "(1, 3, 1, 1, 3, 6)\n"
     ]
    }
   ],
   "source": [
    "#tile it \n",
    "# Flatten it for reason of too much dimension.\n",
    "sequence_rev_reshape = tf.reshape(sequence_rev, (1, 1, 1, 1, 1, level*(level-1)))\n",
    "sequence_rev_reshape_tile = tf.tile(sequence_rev_reshape, [batch, sub_row, sub_column, channel, level, 1])\n",
    "sequence_rev_reshaped_tile = tf.reshape(sequence_rev_reshape_tile, (batch, sub_row, sub_column, channel, level, level, level-1))\n",
    "\n",
    "print(\"sequence_rev_reshape\")\n",
    "print(K.eval(sequence_rev_reshape))\n",
    "\n",
    "print(sequence_rev_reshape_tile.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLCM_Denominator.shape: \n",
      "(1, 3, 1, 1, 3, 3)\n",
      "GLCM_Numerator_1.shape: \n",
      "(1, 3, 1, 1, 3, 3)\n",
      "\n",
      "\n",
      "GLCM_subarray: \n",
      "(1, 3, 1, 1, 3, 3)\n",
      "GLCM_subarray_2\n",
      "[[[[[[ 0. -0.  1.]\n",
      "     [ 0. -0.  1.]\n",
      "     [ 0. -0.  1.]]]]\n",
      "\n",
      "\n",
      "\n",
      "  [[[[ 1. -0.  0.]\n",
      "     [ 1. -0.  0.]\n",
      "     [ 1. -0.  0.]]]]\n",
      "\n",
      "\n",
      "\n",
      "  [[[[ 0. -0.  1.]\n",
      "     [ 0. -0.  1.]\n",
      "     [ 0. -0.  1.]]]]]]\n"
     ]
    }
   ],
   "source": [
    "#Lagrange polynomials Denominator\n",
    "GLCM_t = tf.tile(tf.reshape(sequence, (1, 1, 1, 1, level*(level-1))), [batch, sub_row, sub_column, channel, level])\n",
    "GLCM_t_reshape = tf.reshape(GLCM_t, (batch, sub_row, sub_column, channel, level, level, (level-1)))\n",
    "GLCM_Denominator_array = GLCM_t_reshape-sequence_rev_reshaped_tile\n",
    "GLCM_Denominator = tf.reduce_prod(GLCM_Denominator_array, axis=6)\n",
    "\n",
    "print(\"GLCM_Denominator.shape: \")\n",
    "print(GLCM_Denominator.shape)\n",
    "\n",
    "#print(\"GLCM_Denominator[0][0][0]\")\n",
    "#print(K.eval(GLCM_Denominator[0][0][0]))\n",
    "\n",
    "#Lagrange polynomials Numerator\n",
    "GLCM_Numerator_1_array = reshape_tiled_subarray_1-sequence_rev_reshaped_tile\n",
    "GLCM_Numerator_2_array = reshape_tiled_subarray_2-sequence_rev_reshaped_tile\n",
    "\n",
    "GLCM_Numerator_1 = tf.reduce_prod(GLCM_Numerator_1_array, axis=6)\n",
    "GLCM_Numerator_2 = tf.reduce_prod(GLCM_Numerator_2_array, axis=6)\n",
    "\n",
    "print(\"GLCM_Numerator_1.shape: \")\n",
    "print(GLCM_Numerator_1.shape)\n",
    "print(\"\\n\")\n",
    "\n",
    "GLCM_subarray_1 = GLCM_Numerator_1/GLCM_Denominator\n",
    "GLCM_subarray_2 = GLCM_Numerator_2/GLCM_Denominator\n",
    "print(\"GLCM_subarray: \")\n",
    "print(GLCM_subarray_1.shape)\n",
    "\n",
    "print(\"GLCM_subarray_2\")\n",
    "print(K.eval(GLCM_subarray_2 ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLCM_single_entry1: \n",
      "[[[[[[ 0. -0.  1.]\n",
      "     [ 0. -0.  1.]\n",
      "     [ 0. -0.  1.]]]]\n",
      "\n",
      "\n",
      "\n",
      "  [[[[ 0. -0.  1.]\n",
      "     [ 0. -0.  1.]\n",
      "     [ 0. -0.  1.]]]]\n",
      "\n",
      "\n",
      "\n",
      "  [[[[ 0. -0.  1.]\n",
      "     [ 0. -0.  1.]\n",
      "     [ 0. -0.  1.]]]]]]\n",
      "GLCM_single_entry2_transpose: \n",
      "[[[[[[ 0.  0.  0.]\n",
      "     [-0. -0. -0.]\n",
      "     [ 1.  1.  1.]]]]\n",
      "\n",
      "\n",
      "\n",
      "  [[[[ 1.  1.  1.]\n",
      "     [-0. -0. -0.]\n",
      "     [ 0.  0.  0.]]]]\n",
      "\n",
      "\n",
      "\n",
      "  [[[[ 0.  0.  0.]\n",
      "     [-0. -0. -0.]\n",
      "     [ 1.  1.  1.]]]]]]\n"
     ]
    }
   ],
   "source": [
    "# Now, we need to do logic checking and merging on our subarrays to get the final GLCM.\n",
    "\n",
    "# a and b = a*b\n",
    "# We have to do transpose on GLCM_subarray_2 for its different location with GLCM_subarray_1 in GLCM. \n",
    "\n",
    "GLCM_subarray_2_transpose = tf.transpose(GLCM_subarray_2, perm=[0, 1, 2, 3, 5, 4])\n",
    "GLCM_single_entry = tf.multiply(GLCM_subarray_1, GLCM_subarray_2_transpose)\n",
    "print(\"GLCM_single_entry1: \")\n",
    "print(K.eval(GLCM_subarray_1))\n",
    "print(\"GLCM_single_entry2_transpose: \")\n",
    "print(K.eval(GLCM_subarray_2_transpose))\n",
    "\n",
    "# sum single entries to get the final GLCM.\n",
    "GLCM = tf.reduce_sum(GLCM_single_entry, axis=[1, 2])\n",
    "\n",
    "if symmetric:\n",
    "    GLCM = GLCM+tf.transpose(GLCM, perm=[0, 1, 3, 2])\n",
    "if normed:\n",
    "    GLCM = GLCM/tf.reduce_sum(GLCM)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0.          0.          0.16666667]\n",
      "   [ 0.          0.          0.        ]\n",
      "   [ 0.16666667  0.          0.66666667]]]]\n"
     ]
    }
   ],
   "source": [
    "print(K.eval(GLCM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'float64'>\n"
     ]
    }
   ],
   "source": [
    "print(GLCM.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.constant([[[ 1,  2,  3],\n",
    "                  [ 4,  5,  6]],\n",
    "                 [[ 7,  8,  9],\n",
    "                  [10, 11, 12]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(2), Dimension(2), Dimension(3)])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(2), Dimension(3), Dimension(2)])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.transpose(x, perm=[0, 2, 1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
